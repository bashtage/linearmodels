#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
\noindent
Formulas and Mathematical Detail
\end_layout

\begin_layout Subsection*
\noindent
Notation
\end_layout

\begin_layout Standard
\noindent
Interest is in recovering the parameter vector from the model 
\begin_inset Formula 
\begin{align*}
y_{i} & =\beta^{\prime}x_{i}+\epsilon_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\beta$
\end_inset

 is 
\begin_inset Formula $k$
\end_inset

 by 1, 
\begin_inset Formula $x_{i}$
\end_inset

 is a 
\begin_inset Formula $k$
\end_inset

 by 1 vector of observable variables and 
\begin_inset Formula $\epsilon_{i}$
\end_inset

 is a scalar error.
 
\begin_inset Formula $x_{i}$
\end_inset

 can be separated in two types of variables.
 The 
\begin_inset Formula $k_{1}$
\end_inset

 by 1 set of variables 
\begin_inset Formula $x_{1i}$
\end_inset

 are exogenous regressors in the sense that 
\begin_inset Formula $E\left[x_{1i}\epsilon_{i}\right]=0$
\end_inset

.
 The 
\begin_inset Formula $k_{2}$
\end_inset

 by 1 variables 
\begin_inset Formula $x_{2i}$
\end_inset

 are endogenous.
 A set of 
\begin_inset Formula $p$
\end_inset

 instruments is available that satisfy the requirements for validity where
 
\begin_inset Formula $p\geq k_{2}$
\end_inset

.
 The extended model can be written as 
\begin_inset Formula 
\begin{align*}
y_{i} & =\underset{\textrm{exogenous}}{\underbrace{\beta_{1}^{\prime}x_{1i}}}+\underset{\textrm{endogenous}}{\underbrace{\beta_{2}^{\prime}x_{2i}}}+\epsilon_{i}\\
x_{2i} & =\underset{\textrm{exogenous}}{\underbrace{\gamma_{1}^{\prime}z_{1i}}}+\underset{\textrm{instruments}}{\underbrace{\gamma_{2}^{\prime}z_{2i}}}+u_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
The model can be expressed compactly 
\begin_inset Formula 
\begin{align*}
Y & =X_{1}\beta_{1}+X_{2}\beta_{1}+\epsilon=X\beta+\epsilon\\
X_{2} & =Z_{1}\gamma_{1}+Z_{2}\gamma_{2}+u=Z\gamma+u
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
The vector of instruments 
\begin_inset Formula $z_{i}$
\end_inset

 is 
\begin_inset Formula $p$
\end_inset

 by 1.
 There are 
\begin_inset Formula $n$
\end_inset

 observations for all variables.
 
\begin_inset Formula $k_{c}=1$
\end_inset

 if the model contains a constant (either explicit or implicit, i.e., including
 all categories of a dummy variable).
 The constant, if included, is in 
\begin_inset Formula $x_{1i}$
\end_inset

.
 
\begin_inset Formula $X$
\end_inset

 is the 
\begin_inset Formula $n$
\end_inset

 by 
\begin_inset Formula $k$
\end_inset

 matrix if regressors where row 
\begin_inset Formula $i$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula $x_{i}^{\prime}$
\end_inset

.
 
\begin_inset Formula $X$
\end_inset

 can be partitioned into 
\begin_inset Formula $\left[X_{1}\;X_{2}\right]$
\end_inset

.
 
\begin_inset Formula $Z$
\end_inset

 is the 
\begin_inset Formula $n$
\end_inset

 by 
\begin_inset Formula $p$
\end_inset

 matrix of instruments.
 The vector 
\begin_inset Formula $y$
\end_inset

 is 
\begin_inset Formula $n$
\end_inset

 by 1.
 Projection matrices for 
\begin_inset Formula $X$
\end_inset

 is defined 
\begin_inset Formula $P_{X}=X\left(X^{\prime}X\right)^{-1}X^{\prime}$
\end_inset

.
 The projection matrix for 
\begin_inset Formula $Z$
\end_inset

 is similarly defined only using 
\begin_inset Formula $Z$
\end_inset

.
 The annihilator matrix for 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula $M_{X}=I-P_{X}$
\end_inset

.
\end_layout

\begin_layout Subsection*
\noindent
Parameter Estimation
\end_layout

\begin_layout Subsubsection*
\noindent
Two-stage Least Squares (2SLS)
\end_layout

\begin_layout Standard
\noindent
The 2SLS estimator is 
\begin_inset Formula 
\begin{align*}
\hat{\beta}_{2SLS} & =\left(X^{\prime}P_{Z}X\right)^{-1}\left(X^{\prime}P_{Z}y\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
\noindent
Limited Information Maximum Likelihood and k-class Estimators
\end_layout

\begin_layout Standard
\noindent
The LIML or other k-class estimator is 
\begin_inset Formula 
\begin{align*}
\hat{\beta}_{\kappa} & =\left(X^{\prime}\left(I-\kappa M_{Z}\right)X\right)^{-1}\left(X^{\prime}\left(I-\kappa M_{Z}\right)y\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\kappa$
\end_inset

 is the parameter of the class.
 When 
\begin_inset Formula $\kappa=1$
\end_inset

 the 2SLS estimator is recovered.
 When 
\begin_inset Formula $\kappa=0$
\end_inset

, the OLS estimator is recovered.
 The LIML estimator is recovered when 
\begin_inset Formula $\kappa$
\end_inset

 set to 
\begin_inset Formula 
\[
\hat{\kappa}=\min\mathrm{eig\left[\left(W^{\prime}M_{Z}W\right)^{-\frac{1}{2}}\left(W^{\prime}M_{X_{1}}W\right)\left(W^{\prime}M_{Z}W\right)^{-\frac{1}{2}}\right]}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $W=\left[y\:X_{2}\right]$
\end_inset

 and 
\begin_inset Formula $\mathrm{eig}$
\end_inset

 returns the eigenvalues.
 
\end_layout

\begin_layout Subsubsection*
\noindent
Generalized Method of Moments (GMM)
\end_layout

\begin_layout Standard
\noindent
The GMM estimator is defined as 
\begin_inset Formula 
\begin{align*}
\hat{\beta}_{GMM} & =\left(X^{\prime}ZWZ^{\prime}X\right)^{-1}\left(X^{\prime}ZWZ^{\prime}y\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $W$
\end_inset

 is a positive definite weighting matrix.
 
\end_layout

\begin_layout Subsubsection*
\noindent
Continuously Updating Generalized Method of Moments (GMM-CUE)
\end_layout

\begin_layout Standard
\noindent
The continuously updating GMM estimator solves the minimization problem
\begin_inset Formula 
\[
\min_{\beta}n\bar{g}\left(\beta\right)^{\prime}W\left(\beta\right)^{-1}\bar{g}\left(\beta\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\bar{g}\left(\beta\right)=n^{-1}\sum_{i=1}^{n}z_{i}\hat{\epsilon}_{i}$
\end_inset

 and 
\begin_inset Formula $\hat{\epsilon}_{i}=y_{i}-x_{i}\beta$
\end_inset

.
 Unlike standard GMM, the weight matrix, 
\begin_inset Formula $W$
\end_inset

 directly depends on the model parameters 
\begin_inset Formula $\beta$
\end_inset

 and so it is not possible to use a closed form estimator.
 
\end_layout

\begin_layout Subsection*
\noindent
Basic Statistics
\end_layout

\begin_layout Standard
\noindent
Let 
\begin_inset Formula $\hat{\epsilon}=y-X\hat{\beta}$
\end_inset

.
 The residual sum of squares (RSS) is 
\begin_inset Formula $\hat{\epsilon}^{\prime}\hat{\epsilon}$
\end_inset

, the model sum of squares (MSS) is 
\begin_inset Formula $\hat{\beta}^{\prime}X^{\prime}X\hat{\beta}$
\end_inset

 and the total sum of squares (TSS) is 
\begin_inset Formula $\left(y-k_{c}\bar{y}\right)^{\prime}\left(y-k_{c}\bar{y}\right)^{\prime}$
\end_inset

where 
\begin_inset Formula $\bar{y}$
\end_inset

 is the sample average of 
\begin_inset Formula $y$
\end_inset

.
 The model 
\begin_inset Formula $R^{2}$
\end_inset

is defined
\begin_inset Formula 
\begin{align*}
R^{2} & =1-\frac{\hat{\epsilon}^{\prime}\hat{\epsilon}}{\left(y-k_{c}\bar{y}\right)^{\prime}\left(y-k_{c}\bar{y}\right)^{\prime}}=1-\frac{RSS}{TSS}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
and the adjusted 
\begin_inset Formula $R^{2}$
\end_inset

 is defined 
\begin_inset Formula 
\begin{align*}
\bar{R}^{2} & =1-\left(1-R^{2}\right)\frac{N-k_{c}}{N-k}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
The residual variance is 
\begin_inset Formula $s^{2}=n^{-1}\hat{\epsilon}^{\prime}\hat{\epsilon}$
\end_inset

 unless the debiased flag is used, in which case a small sample adjusted
 version is estimated 
\begin_inset Formula $s^{2}=\left(n-k\right)^{-1}\hat{\epsilon}^{\prime}\hat{\epsilon}$
\end_inset

.
 The model degree of freedom is 
\begin_inset Formula $k$
\end_inset

 and the residual degree of freedom is 
\begin_inset Formula $n-k$
\end_inset

.
 
\end_layout

\begin_layout Standard
\noindent
The model F-statistic is defined 
\begin_inset Formula 
\begin{align*}
F & =\hat{\beta}_{-}^{\prime}\hat{V}_{-}^{-1}\dot{\hat{\beta}_{-}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where the notation 
\begin_inset Formula $\hat{\beta}_{-}$
\end_inset

 indicates that the constant is excluded from 
\begin_inset Formula $\hat{\beta}$
\end_inset

 and 
\begin_inset Formula $\hat{V}_{-}$
\end_inset

 indicates that the row and column corresponding to a constant are excluded.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
If the model contains an implicit constant, e.g., all categories of a dummy,
 one of the categories is excluded when computing the test statistic.
 The choice of category to drop has no effect and is equivalent to reparameteriz
ing the model with a constant and excluding one category of dummy.
\end_layout

\end_inset

 The test statistic is distributed as 
\begin_inset Formula $\chi_{k-k_{c}}^{2}.$
\end_inset

 If the debiased flag is set, then the test statistic 
\begin_inset Formula $F$
\end_inset

 is transformed as 
\begin_inset Formula $F/\left(k-k_{c}\right)$
\end_inset

 and a 
\begin_inset Formula $F_{k-k_{c},n-k}$
\end_inset

 distribution is used.
 
\end_layout

\begin_layout Subsection*
\noindent
Parameter Covariance Estimation
\end_layout

\begin_layout Subsubsection*
\noindent
Two-stage LS, LIML and k-class estimators
\end_layout

\begin_layout Standard
\noindent
Four covariance estimators are available.
 The first is the standard homoskedastic covariance, defined as 
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\begin{align*}
\hat{\Sigma}=n^{-1}s^{2}\left(\frac{X^{\prime}\left(I-\kappa M_{z}\right)X}{n}\right)^{-1} & =n^{-1}s^{2}\hat{A}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Note that this estimator can be expressed as 
\begin_inset Formula 
\begin{align*}
\hat{\Sigma}=n^{-1}\hat{A}^{-1}\left\{ s^{2}\hat{A}\right\} \hat{A}^{-1} & =n^{-1}\hat{A}^{-1}\hat{B}\hat{A}^{-1}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
All estimators take this form and only differ in how the asymptotic covariance
 of the scores, 
\begin_inset Formula $B$
\end_inset

, is estimated.
 For the homoskedastic covariance estimator, 
\begin_inset Formula $\hat{B}=s^{2}\hat{A}.$
\end_inset

 The score covariance in the heteroskedasticity robust covariance estimator
 is 
\begin_inset Formula 
\begin{align*}
\hat{B} & =n^{-1}\sum_{i=1}^{n}\hat{\epsilon}_{i}^{2}\hat{x}_{i}\hat{x}_{i}^{\prime}=n^{-1}\sum_{i=1}^{n}\hat{\xi}_{i}\hat{\xi}_{i}^{\prime}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\hat{x_{i}}$
\end_inset

 is row 
\begin_inset Formula $i$
\end_inset

 of 
\begin_inset Formula $\hat{X}=P_{Z}X$
\end_inset

 and 
\begin_inset Formula $\hat{\xi}_{i}=\hat{\epsilon}_{i}\hat{x}_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
The kernel covariance estimator is robust to both heteroskedasticity and
 autocorrelation and is defined as 
\begin_inset Formula 
\begin{align*}
\hat{B} & =\hat{\Gamma}_{0}+\sum_{i=1}^{n-1}K\left(\frac{i}{h}\right)\left(\hat{\Gamma}_{i}+\hat{\Gamma}_{i}^{\prime}\right)\\
\hat{\Gamma_{j}} & =n^{-1}\sum_{i=j+1}^{n}\hat{\xi}_{i-j}\hat{\xi}_{i}^{\prime}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $K\left(\frac{i}{h}\right)$
\end_inset

 is a kernel weighting function where 
\begin_inset Formula $h$
\end_inset

 is the kernel bandwidth.
 
\end_layout

\begin_layout Standard
\noindent
The one-way clustered covariance estimator is defined as 
\begin_inset Formula 
\begin{align*}
n^{-1}\sum_{j=1}^{g}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}\right)\left(\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}\right)^{\prime}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}$
\end_inset

 is the sum of the scores for all members in group 
\begin_inset Formula $\mathcal{G}_{j}$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 is the number of groups.
 
\end_layout

\begin_layout Standard
\noindent
If the debiased flag is used to perform a small-sample adjustment, all estimator
s except the clustered covariance are rescaled by 
\begin_inset Formula $\left(n-k\right)/n$
\end_inset

.
 The clustered covariance is rescaled by 
\begin_inset Formula $\left(\left(n-k\right)\left(n-1\right)/n^{2}\right)\left(\left(g-1\right)/g\right)$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
This somewhat non-obvious choice is driven by Stata compatibility.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
\noindent
Standard Errors
\end_layout

\begin_layout Standard
\noindent
Standard errors are defined as 
\begin_inset Formula 
\[
s.e.\left(\hat{\beta}_{j}\right)=\sqrt{e_{j}^{\prime}\hat{\Sigma}e_{j}}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $e_{j}$
\end_inset

 is a vector of 0s except in location 
\begin_inset Formula $j$
\end_inset

 which is 1.
\end_layout

\begin_layout Subsubsection*
\noindent
T-statistics
\end_layout

\begin_layout Standard
\noindent
T-statistics test the null 
\begin_inset Formula $H_{0}:\beta_{j}=0$
\end_inset

 against a 2-sided alternative and are defined as 
\begin_inset Formula 
\[
z=\frac{\hat{\beta}_{j}}{s.e.\left(\hat{\beta}_{j}\right)}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\noindent
P-values
\end_layout

\begin_layout Standard
\noindent
P-values are computes using 2-sided tests, 
\begin_inset Formula 
\[
Pr\left(\left|z\right|>Z\right)=2-2\Phi\left(\left|z\right|\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
If the covariance estimator was debiased, a Student's t distribution with
 
\begin_inset Formula $n-k$
\end_inset

 degrees of freedom is used, 
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\begin{align*}
Pr\left(\left|z\right|>Z\right) & =2-2t_{n-k}\left(\left|z\right|\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $t_{n-k}\left(\cdot\right)$
\end_inset

 is the CDF of a Student's T distribution.
\end_layout

\begin_layout Subsubsection*
\noindent
Confidence Intervals
\end_layout

\begin_layout Standard
\noindent
Confidence intervals are constructed as 
\begin_inset Formula 
\[
CI_{i,1-\alpha}=\hat{\beta}_{i}\pm q_{\alpha/2}\times\hat{\sigma}_{\beta_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $q_{\alpha/2}$
\end_inset

 is the 
\begin_inset Formula $\alpha/2$
\end_inset

 quantile of a standard Normal distribution or a Student's t.
 The Student's t is used when a debiased covariance estimator is used.
\end_layout

\begin_layout Subsubsection*
\noindent
Linear Hypothesis Tests
\end_layout

\begin_layout Standard
\noindent
Linear hypothesis tests examine the validity of nulls of the form 
\begin_inset Formula $H_{0}:R\beta-r=0$
\end_inset

 and are implemented using a Wald test statistic
\begin_inset Formula 
\[
W=\left(R\hat{\beta}-r\right)^{\prime}\left[R^{\prime}\hat{\Sigma}R\right]^{-1}\left(R\hat{\beta}-r\right)\sim\chi_{q}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $q$
\end_inset

 is the 
\begin_inset Formula $rank\left(R\right)$
\end_inset

 which is usually the number of rows in 
\begin_inset Formula $R$
\end_inset

 .
 If the debiased flag is used, then 
\begin_inset Formula $W/q$
\end_inset

 is reported and critical and p-values are taken from a 
\begin_inset Formula $F_{q,n-k}$
\end_inset

 distribution.
 
\end_layout

\begin_layout Subsubsection*
\noindent
GMM Covariance estimators
\end_layout

\begin_layout Standard
\noindent
GMM covariance depends on the weighting matrix used in estimation and the
 assumed covariance of the scores.
 In most applications these are the same and so the inefficient form, 
\begin_inset Formula 
\[
\hat{\Sigma}=n^{-1}\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}\left(\left(\frac{X'Z}{n}\right)WSW\left(\frac{Z'X}{n}\right)\right)\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
will collapse to the simpler form 
\begin_inset Formula 
\[
\hat{\Sigma}=n^{-1}\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
when 
\begin_inset Formula $W=S^{-1}$
\end_inset

.
 When an unadjusted (homoskedastic) covariance is used, 
\begin_inset Formula 
\[
\hat{S}=\tilde{s}^{2}n^{-1}\sum_{j=1}^{n}z_{j}^{\prime}z_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\tilde{s}^{2}=n^{-1}\sum_{i=1}^{n}\left(\epsilon_{i}-\bar{\epsilon}\right)^{2}$
\end_inset

 subtracts the mean which may be non-zero if the model is overidentified.
 Like previous covariance estimators, if the debiased flag is used, 
\begin_inset Formula $n^{-1}$
\end_inset

 is replaced by 
\begin_inset Formula $\left(n-k\right)^{-1}$
\end_inset

.
 When a robust (heteroskedastic) covariance is used, the estimator of 
\begin_inset Formula $S$
\end_inset

 is modified to 
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\[
\hat{S}=n^{-1}\sum_{i=1}^{n}\hat{\epsilon}_{i}^{2}z_{i}^{\prime}z_{i}.
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
If the debiased flag is used, 
\begin_inset Formula $n^{-1}$
\end_inset

 is replaced by 
\begin_inset Formula $\left(n-k\right)^{-1}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Kernel covariance estimators of 
\begin_inset Formula $S$
\end_inset

 take the form 
\begin_inset Formula 
\begin{align*}
\hat{S} & =\hat{\Gamma}_{0}+\sum_{i=1}^{n-1}k\left(i/h\right)\left(\hat{\Gamma}_{i}+\hat{\Gamma}_{i}^{\prime}\right)\\
\hat{\Gamma_{j}} & =n^{-1}\sum_{i=j+1}^{n}\hat{\epsilon}_{i-j}\hat{\epsilon}_{i}z_{i-j}^{\prime}z_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
and 
\begin_inset Formula $k\left(\cdot\right)$
\end_inset

 is a kernel weighting function with bandwidth 
\begin_inset Formula $h$
\end_inset

.
 If the debiased flag is used, 
\begin_inset Formula $n^{-1}$
\end_inset

 is replaced by 
\begin_inset Formula $\left(n-k\right)^{-1}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\noindent
The one-way clustered covariance estimator is defined as 
\begin_inset Formula 
\[
\hat{S}=n^{-1}\sum_{j=1}^{g}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}\right)^{\prime}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}$
\end_inset

 is the sum of the moment conditional for all members in group 
\begin_inset Formula $\mathcal{G}_{j}$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 is the number of groups.
 If the debiased flag is used, the 
\begin_inset Formula $n^{-1}$
\end_inset

 term is replaced by 
\begin_inset Formula 
\[
\left(n-k\right)^{-1}\frac{n-1}{n}\frac{g}{g-1}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\noindent
GMM Weight Estimators
\end_layout

\begin_layout Standard
\noindent
The GMM optimal weight estimators are identical to the the estimators of
 
\begin_inset Formula $S$
\end_inset

 with two notable exceptions.
 First, they are never debiased and so always use 
\begin_inset Formula $n^{-1}$
\end_inset

.
 Second, if the center flag is true, the demeaned moment conditions defined
 as 
\begin_inset Formula $\tilde{g}_{i}=z_{i}\hat{\epsilon}_{i}-\overline{z\epsilon}$
\end_inset

 are used in-place of 
\begin_inset Formula $g_{i}$
\end_inset

 in the robust, kernel and clustered estimators.
 The unadjusted estimator is always centered, and so this option has no
 effect.
 
\end_layout

\begin_layout Subsection*
\noindent
Post-estimation
\end_layout

\begin_layout Subsubsection*
\noindent
2SLS and LIML Post-estimation Results
\end_layout

\begin_layout Standard
\noindent

\series bold
Sargan
\end_layout

\begin_layout Standard
\noindent
Sargan's test of over-identifying restrictions examines whether the variance
 of the IV residuals is similar to that of the OLS residuals.
 The test statistic is computed 
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\[
s=n(1-\hat{\epsilon}^{\prime}M_{Z}\hat{\epsilon}/\hat{\epsilon}^{\prime}\hat{\epsilon})\sim\chi_{v}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\hat{\epsilon}$
\end_inset

 are the IV residuals and 
\begin_inset Formula $M_{Z}$
\end_inset

 is the annihilator matrix using all exogenous variables.
\begin_inset Formula $\nu$
\end_inset

 is the number of overidentifying restrictions, which is the number of instrumen
ts minus the number of endogenous variables, 
\begin_inset Formula $p-k_{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\noindent

\series bold
Basmann
\end_layout

\begin_layout Standard
\noindent
Basmann's test is a small-sample corrected version of Sargan's test of over-iden
tifying restrictions.
 It has the same distribution.
 Let 
\begin_inset Formula $s$
\end_inset

 be Sargan's test statistic, then Basmann's test statistic is 
\begin_inset Formula 
\[
s(n-p)/(n-s)\sim\chi_{v}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent

\series bold
Wooldridge score
\end_layout

\begin_layout Standard
\noindent
Wooldridge's score test of exogeneity examines the magnitude of the correlation
 between the OLS residuals and a an appropriately constructed set of residuals
 of the instruments.
 Define 
\begin_inset Formula $e=M_{X}Y$
\end_inset

 and 
\begin_inset Formula $\nu=M_{X}M_{Z}X_{2}$
\end_inset

.
 Then the test statistic is computed from the regression
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\[
1=\gamma_{1}\hat{\epsilon}_{1}\hat{v}_{1,i}+\ldots+\gamma_{p}\hat{\epsilon}_{1}\hat{v}_{p,i}+\eta_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
as 
\begin_inset Formula $nR^{2}\sim\chi_{k_{2}}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent

\series bold
Wooldridge regression
\end_layout

\begin_layout Standard
\noindent
Wooldridge's regression test of exogeneity is closely related to the score
 test and is generally more powerful.
 It also inherits robustness to heteroskedasticity and/or autocorrelation
 the comes from the choice of covariance estimator used in the model.
 Define 
\begin_inset Formula $R=M_{Z}X_{2}$
\end_inset

.
 The test is implemented in a regression of 
\begin_inset Formula 
\[
Y=X\beta+R\gamma+\eta
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
as
\begin_inset Formula 
\[
\hat{\gamma}^{\prime}\hat{\Sigma}_{\gamma}^{-1}\gamma^{\prime}\sim\chi_{k_{2}}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\hat{\Sigma}_{\gamma}$
\end_inset

 is the block of the covariance matrix corresponding to the 
\begin_inset Formula $\gamma$
\end_inset

 parameters.
 
\begin_inset Formula $\hat{\Sigma}$
\end_inset

 is estimated using the same covariance estimator as the model fit.
\end_layout

\begin_layout Standard
\noindent

\series bold
Wooldridge's Test of Overidentifying restrictions
\end_layout

\begin_layout Standard
\noindent
Wooldridge's test is a score test examining whether the component of the
 instrument that is uncorrelated with both the included exogenous and the
 fitted exogenous is uncorrelated with the IV residuals.
 Define 
\begin_inset Formula $\tilde{Z}=M_{\left[X_{1}\:\hat{X}_{2}\right]}Z_{2,1:q}$
\end_inset

 where 
\begin_inset Formula $\hat{X_{2}}$
\end_inset

 are the fitted values from the first stage regression of the endogenous
 on all exogenous variables and 
\begin_inset Formula $Z_{2,1:q}$
\end_inset

 contains any 
\begin_inset Formula $q$
\end_inset

 columns of 
\begin_inset Formula $Z_{2}$
\end_inset

, 
\begin_inset Formula $q=p-k_{2}$
\end_inset

 .
 The test statistic is computed using a regression of 1s on the test functions
 
\begin_inset Formula $\hat{\epsilon}_{i}\tilde{z}_{i,j}$
\end_inset

 for 
\begin_inset Formula $j=1,\ldots,q$
\end_inset

 which should have expected value 0.
 
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\[
1=\gamma_{1}\hat{\epsilon}_{i}\tilde{z}_{i,1}+\ldots+\gamma_{q}\hat{\epsilon}_{i}\tilde{z}_{i,q}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
The test statistic is 
\begin_inset Formula $nR^{2}\sim\chi_{q}^{2}$
\end_inset

 from the regression.
\end_layout

\begin_layout Standard
\noindent

\series bold
Anderson-Rubin
\end_layout

\begin_layout Standard
\noindent
\align left
The Andersen-Rubin test of overidentification examines the magnitude of
 the LIML 
\begin_inset Formula $\hat{\kappa}$
\end_inset

which should be close to unity when the model is not overidentified.
\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Formula 
\[
n\ln(\hat{\kappa})\sim\chi_{q}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align left
where 
\begin_inset Formula $q=p-k_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent

\series bold
Basman's F
\end_layout

\begin_layout Standard
\noindent
Banmann's F test of overidentification also examines the magnitude of the
 LIML 
\begin_inset Formula $\hat{\kappa}$
\end_inset

.
 The test statistic is 
\begin_inset Formula 
\[
\hat{\kappa}(n-p)/q\sim F_{q,n-n_{instr}}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $q=p-k_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent

\series bold
Durbin and Wu-Haussman
\end_layout

\begin_layout Standard
\noindent
Durbin's and the Wu-Hausmann tests of exogeneity test of exogeneity is depends
 on the variance of the residuals when come endogenous variables are treated
 as exogenous against the case where they are treated as endogenous.
 Durbin's test statistic is
\begin_inset Formula 
\begin{align*}
\delta= & \hat{\epsilon}'_{e}P_{[z,w]}\hat{\epsilon}_{e}-\hat{\epsilon}'_{c}P_{z}\hat{\epsilon}_{c}\\
D= & \delta/(\hat{\epsilon}'_{e}\hat{\epsilon}_{e})/n\sim\chi_{q}^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
and the Wu-Hausmann test statistic is
\end_layout

\begin_layout Standard
\noindent
\begin_inset Formula 
\begin{align*}
WH= & \frac{\delta/q}{(\hat{\epsilon}'_{e}\hat{\epsilon}_{e}-\delta)/v}\sim F_{q,\nu}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\hat{\epsilon}_{e}$
\end_inset

 treats the selected set of endogenous variables as exogenous (efficient
 estimate) and 
\begin_inset Formula $\hat{\epsilon}_{c}$
\end_inset

 is a consistent estimator if these variables are endogenous.
\begin_inset Formula $P_{\left[Z\,W\right]}$
\end_inset

 is the projection matrix containing all exogenous variables including the
 instrument as well as the variables being tested for endogeneity 
\begin_inset Formula $\left(W\right)$
\end_inset

.
\begin_inset Formula $q$
\end_inset

 is the number of variables being tested for exogeneity and 
\begin_inset Formula $\nu=n-k1-k2-q$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
\noindent
GMM Post-estimation Results
\end_layout

\begin_layout Standard
\noindent

\series bold
J-stat
\end_layout

\begin_layout Standard
\noindent
The J-statistic tests whether the model is over-identified, and is defined
 
\begin_inset Formula 
\[
n\bar{g}'W^{-1}\bar{g}\sim\chi_{q}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\bar{g}=n^{-1}\sum\hat{\epsilon}_{i}z_{i}$
\end_inset

 and 
\begin_inset Formula $W$
\end_inset

 is a consistent estimator of the variance of 
\begin_inset Formula $\sqrt{n}\bar{g}$
\end_inset

.
 The degree of freedom is 
\begin_inset Formula $q=p-k_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent

\series bold
C-stat
\end_layout

\begin_layout Standard
\noindent
The C-statistic tests exogeneity by treating a the set of endogenous variables
 as exogenous.
 In practice this means that are included in the GMM moment conditions,
 and so a likelihood-ratio-like test statistic can be computed as 
\begin_inset Formula 
\[
J_{e}-J_{c}\sim\chi_{m}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $J_{e}$
\end_inset

 is the J-statistic treating the tested variables as exogenous and 
\begin_inset Formula $J_{c}$
\end_inset

 leaves then as endogenous.
 The optimal weighting matrix is computed from the expanded model (efficient)
 and used to estimate parameters in both models.
 This ensures that the test statistic is positive.
 
\end_layout

\begin_layout Subsection*
\noindent
First-stage Estimation Analysis
\end_layout

\begin_layout Standard
\noindent

\series bold
Partial R2 and Partial F-statistic
\end_layout

\begin_layout Standard
\noindent
The 
\begin_inset Formula $R^{2}$
\end_inset

 is reported after orthogonalizing the instruments from included exogenous
 variables, so that the model estimated is 
\begin_inset Formula 
\[
x_{2i}=\gamma_{0}+\tilde{z}_{2i}\gamma+\eta_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\tilde{Z}_{2}=M_{X_{1}}\tilde{Z}$
\end_inset

.
 The partial 
\begin_inset Formula $F$
\end_inset

-statistic is the F-statistic from this regression.
 It is implemented as a standard 
\begin_inset Formula $F$
\end_inset

-statistic when the data is assumed to be homoskedastic with an 
\begin_inset Formula $F_{p_{2},n-p_{2}}$
\end_inset

 distribution.
 In all other cases, a quadratic form is used with an asymptotic 
\begin_inset Formula $\chi_{p_{2}}^{2}$
\end_inset

 distribution testing 
\begin_inset Formula $H_{0}:\gamma=0$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent

\series bold
Shea's R2
\end_layout

\begin_layout Standard
\noindent
Shea's 
\begin_inset Formula $R^{2}$
\end_inset

 is defined as the ratio of the parameter variances under OLS and 2SLS estimatio
n standardized by the unexplained variance under each, 
\begin_inset Formula 
\[
\frac{\frac{\hat{\sigma}_{OLS,\beta_{i}}^{2}}{1-R_{OLS}^{2}}}{\frac{\hat{\sigma}_{IV,\beta_{i}}^{2}}{1-R_{IV}^{2}}}=\frac{\hat{\sigma}_{OLS,\beta_{i}}^{2}}{\hat{\sigma}_{IV,\beta_{i}}^{2}}\times\frac{1-R_{IV}^{2}}{1-R_{OLS}^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
If the estimator under 2SLS was as good as under OLS, both ratios would
 be 1 and Shea's 
\begin_inset Formula $R^{2}=1$
\end_inset

.
 On the other hand, the worse the 
\begin_inset Formula $IV$
\end_inset

 fit in terms of either 
\begin_inset Formula $R^{2}$
\end_inset

 or the parameter variances, the lower the value reported by Shea's 
\begin_inset Formula $R^{2}$
\end_inset

.
\end_layout

\begin_layout Subsection*
\noindent
Kernel Weights and Bandwidth Selection
\end_layout

\begin_layout Standard
\noindent

\series bold
Kernel weights
\end_layout

\begin_layout Standard
\noindent
In all formulas, 
\begin_inset Formula $m$
\end_inset

 is the kernel bandwidth parameter.
 
\end_layout

\begin_layout Itemize
Bartlett
\begin_inset Formula 
\[
w_{i}=1-\frac{i}{m+1},\,i<m
\]

\end_inset


\end_layout

\begin_layout Itemize
Parzen
\begin_inset Formula 
\begin{align*}
z_{i} & =\frac{i}{m+1},\,i<m\\
w_{i} & =1-6z_{i}^{2}+6z_{i}^{3},z\leq0.5\\
w_{i} & =2(1-z_{i})^{3},z>0.5
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Quadratic-Spectral
\begin_inset Formula 
\begin{align*}
z_{i} & =\frac{6\pi i}{5m}\\
w_{0} & =1\\
w_{i} & =3(\sin(z_{i})/z_{i}-\cos(z_{i}))/z_{i}^{2},\:i\geq1
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent

\series bold
Optimal BW selection
\end_layout

\begin_layout Standard
\noindent
TODO
\end_layout

\begin_layout Subsection*
\noindent
Constant Detection
\end_layout

\begin_layout Standard
\noindent
Whether a model contains a constant or equivalent is tested using three
 tests.
 These are executed in order and so once a constant is detected, the others
 are not executed.
 The simplest method to ensure that a constant is correctly detected is
 to include a columns of 1s.
 
\end_layout

\begin_layout Enumerate
A column with only 1.0s
\end_layout

\begin_layout Enumerate
A column with a maximum minus minimum equal to 0 and that is not all 0s.
\end_layout

\begin_layout Enumerate
Whether the rank of 
\begin_inset Formula $X$
\end_inset

 is the same as 
\begin_inset Formula $\left[1_{N}\:X\right]$
\end_inset

.
 If these are the same, then the model contains a constant equivalent (e.g.,
 dummies for all categories).
\end_layout

\end_body
\end_document
