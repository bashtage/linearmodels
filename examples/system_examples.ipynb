{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "System regression simultaneously estimates multiple models.  This has three distinct advantages:\n",
    "\n",
    "* Joint inference across models\n",
    "* Linear restrictions can be imposed on the parameters across different models\n",
    "* Improved precision of parameter estimates (depending on the model specification and data)\n",
    "\n",
    "There are $K$ models and each model can be expressed in vector notation as \n",
    "\n",
    "$$ Y_i = X_i\\beta_i + \\epsilon_i$$\n",
    "\n",
    "so that the set of models can be expressed as \n",
    "\n",
    "$$ Y = X\\beta + \\epsilon$$\n",
    "\n",
    "where $Y$ is a column vector that stacks the vectors $Y_i$ for $i=1,2,\\ldots,K$, $X$ is a block-diagonal matrix where the i-th block is $X_i$, $\\beta$ is a stacked vector of the $K$ $\\beta_i$s and $\\epsilon$ is similarly comprised of the stacked columns of $\\epsilon_i$.\n",
    "\n",
    "The model can be estimated using OLS with the usual estimator\n",
    "\n",
    "$$\\hat{\\beta}_{OLS} = \\left(X^\\prime X\\right)^{-1}X^\\prime Y.$$\n",
    "\n",
    "Since there are multiple series, a GLS estimator that accounts for the cross-sectional heteroskedasticity as well as the correlation of residuals can be estimated \n",
    "\n",
    "$$\\hat{\\beta}_{GLS} = \\left(X^\\prime \\Omega^{-1} X\\right)^{-1}X^\\prime  \\Omega^{-1} Y$$\n",
    "\n",
    "where $\\Omega^{-1} = \\Sigma^{-1} \\otimes I_{T}$, $\\Sigma_{ij}$ is the covariance between $\\epsilon_i$ and $\\epsilon_j$ and $T$ is the number of observations. The GLS estimator is only beleficial when the regressors in different models differ  and when residuals are correlated. There GLS estimates are identical to the multivariate OLS estimates when all regressors are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Two data sets will be used.  The first is from Munnell which looks at the effect of capital on state GDP.  This example follows the example in Chapter 10 in recent editions of Greene's _Econometric Analysis_.\n",
    "\n",
    "The data is state-level but the model is estimated in region.  The first step is to aggregate the data by region.  All capital measures are summed and the unemployment rate is averaged using weights porportional to the total employment in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from linearmodels.datasets import munnell\n",
    "data = munnell.load()\n",
    "\n",
    "regions = {\n",
    "    'GF':['AL', 'FL', 'LA', 'MS'],\n",
    "    'MW':['IL', 'IN', 'KY', 'MI', 'MN', 'OH', 'WI'],\n",
    "    'MA':['DE', 'MD', 'NJ', 'NY', 'PA', 'VA'],\n",
    "    'MT' :['CO', 'ID', 'MT', 'ND', 'SD', 'WY'],\n",
    "    'NE' :['CT', 'ME', 'MA', 'NH', 'RI', 'VT'],\n",
    "    'SO' :['GA', 'NC', 'SC', 'TN', 'WV', 'AR'],\n",
    "    'SW' : ['AZ', 'NV', 'NM', 'TX', 'UT'],\n",
    "    'CN': ['AK', 'IA','KS', 'MO','NE','OK'],\n",
    "    'WC': ['CA','OR','WA']\n",
    "}\n",
    "\n",
    "def map_region(state):\n",
    "    for key in regions:\n",
    "        if state in regions[key]:\n",
    "            return key\n",
    "\n",
    "\n",
    "data['REGION'] = data.ST_ABB.map(map_region)\n",
    "data['TOTAL_EMP'] = data.groupby(['REGION','YR'])['EMP'].transform('sum')\n",
    "data['EMP_SHARE'] = data.EMP / data.TOTAL_EMP\n",
    "data['WEIGHED_UNEMP'] = data.EMP_SHARE * data.UNEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `groupby` transformation is used to aggregate the data, and finally all values except the unemployment rate are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = data.groupby(['REGION','YR'])\n",
    "agg_data = grouped[['GSP','PC','HWY','WATER','UTIL','EMP','WEIGHED_UNEMP']].sum()\n",
    "for col in ['GSP','PC','HWY','WATER','UTIL','EMP']:\n",
    "    agg_data['ln'+col] = np.log(agg_data[col])\n",
    "agg_data['UNEMP'] = agg_data.WEIGHED_UNEMP\n",
    "agg_data['Intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Seemingly Unrelated Models are fairly complex and each equation could have a different number of regressors.  As a result, it isn't possibly to use standard `pandas` or `numpy` data structures, and so dictionaries (or technically dictionary-like objects) are used.  In practice, it is strongly recommended to use a `OrderedDictionary` from the `collections` module.  This ensures that equation order will be preserved. In addition, the dictionary must have the following structure:\n",
    "\n",
    "* `keys` **must be strings** and will be used as equation labels\n",
    "* The value associated with each key must be either a dictionary or a tuple.\n",
    "\n",
    "  * When a dictionary is used, it must have two keys, `dependent` and `exog`.  It can optionaly have a third key `weights` which provides weights to use in the regression.\n",
    "  * When a tuple is used, it must have two elements and takes the form `(dependent, exog)`.  It can optionally contains weights in which case it takes the form `(dependent, exog, weights)`.\n",
    "\n",
    "This example uses the dictionary syntax to contain the data for each region and uses the region identified as the equation label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "mod_data = OrderedDict()\n",
    "for region in ['GF','SW','WC','MT','NE','MA','SO','MW','CN']:\n",
    "    region_data = agg_data.loc[region]\n",
    "    dependent = region_data.lnGSP\n",
    "    exog = region_data[['Intercept', 'lnPC', 'lnHWY', 'lnWATER', 'lnUTIL', 'lnEMP', 'UNEMP']]\n",
    "    mod_data[region] = {'dependent': dependent, 'exog': exog}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model is virtually identical to  fitting any other model with the exception of the special data structure required. \n",
    "\n",
    "The fitting options here ensure that the homoskedastic covariance estimator are used (`cov_type='unadjusted'`) and that a small sample adjustment is applied. By default, GLS is used (this can be overridden using `method='ols'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from linearmodels.system import SUR\n",
    "mod = SUR(mod_data)\n",
    "res = mod.fit(cov_type='unadjusted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the requirements for there to be an efficiency gain in a SUR is that the residuals are correlated. A heatmap is used to inspect this correlation, which is substantial and varies by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = res.sigma\n",
    "std = np.sqrt(np.diag(res.sigma)[:,None])\n",
    "regions =  [k for k in mod_data.keys()]\n",
    "corr = pd.DataFrame(cov / (std @ std.T), columns=regions, index=regions)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(corr, vmax=.8, square=True)\n",
    "plt.show()\n",
    "\n",
    "corr.style.format('{:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values can be seen to be identical to the reported results in the existing example from Greene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display_png\n",
    "display_png(Image('correct-greene-table-10-2.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full result is fairly long and so here I only pring the first 33 lines which show results for two regions.  By default it reports all estimates along with the usual measures of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(res.summary.as_text().split('\\n')[:33]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual results are contained in a dictionary located at the attribute `equations` and can be acccessed using equation labels (availablea at the attribute `equation_labels`).  Additional information about the model is presented in this view. The West Coast results are show.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.equations['WC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current version of the model doesn't faciliate cross equaiton comparrisons and so this is manually implemented here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement method to compare across equations\n",
    "params = []\n",
    "for label in res.equation_labels:\n",
    "    params.append(res.equations[label].params)\n",
    "params = pd.concat(params,1)\n",
    "params.columns = res.equation_labels\n",
    "params.T.style.format('{:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results can be compared to the results in Greene -- they are unsurprisingly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_png(Image('correct-greene-table-10-1.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLS estimation method requires stronger assumptions for parameter estiamtes to be consistent.  If these are violated then it might be the case that OLS is still consistent (in some sense) and so OLS can be used by passing `method='ols'` when calling `fit`. \n",
    "\n",
    "These results can be compared simiarly to Greene's table -- they are identical excep tthe final value which seems to have a small typo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ols = mod.fit(method='ols', debiased=True, cov_type='unadjusted')\n",
    "params = []\n",
    "r2 = []\n",
    "for label in res.equation_labels:\n",
    "    params.append(res_ols.equations[label].params)\n",
    "    r2.append(res_ols.equations[label].rsquared)\n",
    "params = pd.concat(params,1)\n",
    "params.columns = res.equation_labels\n",
    "params = params.T\n",
    "params['R2'] = r2\n",
    "params.style.format('{:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estiamtes for one coefficient -- unemployment -- can be compared across the two estimation methods.  \n",
    "\n",
    "**Note**: the standard errors for the GLS estimator differ somewhat from Greene.  This is expected since a slightly different formula for the covariance has been used which is consistent.  In particular, the common estimator takes the form \n",
    "\n",
    "$$ (X^\\prime \\Omega^{-1} X)^{-1} $$\n",
    "\n",
    "where $\\Omega$ is estimated from the first-step regression.  The form used in this package is \n",
    "\n",
    "$$ (X^\\prime \\Omega^{-1} X)^{-1} (X^\\prime S X) (X^\\prime \\Omega^{-1} X)^{-1} $$\n",
    "\n",
    "where $S$ is an estimator of the covariance of the residuals using the GLS parameter estimates. Obviously in the usual form $S=\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: I think this is wrong.  It needs to be checked to ensure that the correct residuals are used!!\n",
    "params = pd.concat([res_ols.params.iloc[1::7], res_ols.std_errors.iloc[1::7], \n",
    " res.params.iloc[1::7], res.std_errors.iloc[1::7]],1)\n",
    "params.columns=['OLS', 'OLS se', 'GLS', 'GLS se']\n",
    "params.index = regions\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_png(Image('correct-greene-table-10-3.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_het = mod.fit(cov_type='robust', debiased=True)\n",
    "print(res_het)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted Residual Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.datasets import fringe\n",
    "fdata = fringe.load()\n",
    "fdata.describe()\n",
    "exog = sm.add_constant(fdata[['educ','exper','expersq','tenure','tenuresq','union','south','nrtheast','nrthcen','married','white','male']])\n",
    "fmod_data = OrderedDict()\n",
    "fmod_data['hrearn'] = {'dependent': fdata.hrearn, 'exog': exog}\n",
    "fmod_data['hrbens'] = {'dependent': fdata.hrbens, 'exog': exog}\n",
    "fmod = SUR(fmod_data)\n",
    "print(fmod.fit(cov_type='unadjusted', debiased=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_earn = sm.add_constant(fdata[['educ','exper','expersq','union','nrtheast','white']])\n",
    "exog_bens = sm.add_constant(fdata[['educ','exper','expersq','tenure','tenuresq','union','male']])\n",
    "fmod_data['hrearn'] = {'dependent': fdata.hrearn, 'exog': exog_earn}\n",
    "fmod_data['hrbens'] = {'dependent': fdata.hrbens, 'exog': exog_bens}\n",
    "fmod = SUR(fmod_data)\n",
    "print(fmod.fit(cov_type='unadjusted', debiased=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmod_res = fmod.fit(cov_type='unadjusted', debiased=True, iterate=True)\n",
    "print(fmod_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmod_res.iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Covariance Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(cov_type='robust',debiased=True)\n",
    "mod.fit(cov_type='robust',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-specified Residual Covariance Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_corr = (corr - np.eye(9)).mean().mean() * (81/72)\n",
    "rho = np.ones((9,9)) * avg_corr  + (1-avg_corr) * np.eye(9)\n",
    "sigma_pre = rho * (std @ std.T)\n",
    "mod_pre_sigma = SUR(mod_data, sigma=sigma_pre)\n",
    "res_pre = mod_pre_sigma.fit(cov_type='unadjusted', debiased=True)\n",
    "print(res_pre.equations['GF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Equation Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.param_names[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(columns=mod.param_names, index=['rest{0}'.format(i) for i in range(1,9)], dtype=np.float64)\n",
    "r.loc[:,:] = 0.0\n",
    "r.iloc[:,6] = -1.0\n",
    "r.iloc[:,13::7] = np.eye(8)\n",
    "print(r.iloc[:,6::7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.zeros((8*6, r.shape[1]))\n",
    "loc = 0\n",
    "for i in range(6):\n",
    "    for j in range(8):\n",
    "        r2[loc,i+1] = -1\n",
    "        r2[loc,7*(j+1) + i+1] = 1\n",
    "        loc += 1\n",
    "r2=pd.DataFrame(r2, columns=mod.param_names)\n",
    "mod.reset_constraints()\n",
    "mod.add_constraints(r2)\n",
    "mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.add_constraints(r)\n",
    "rest_res = mod.fit(cov_type='unadjusted', debiased=True)\n",
    "print(rest_res.params.iloc[6::7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from linearmodels.datasets import french\n",
    "data = french.load()\n",
    "factors = sm.add_constant(data[['MktRF']])\n",
    "mv_ols = SUR.multivariate_ls(data[['S1V1','S1V3','S1V5','S5V1','S5V3','S5V5']], factors)\n",
    "mv_ols_res = mv_ols.fit(cov_type='unadjusted')\n",
    "print(mv_ols_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GLS with common regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mv_ols.fit(cov_type='unadjusted', method='gls'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
